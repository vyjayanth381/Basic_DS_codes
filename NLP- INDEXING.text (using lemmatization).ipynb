{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "#plt.style.use('seaborn')\n",
    "import nltk # natural language tool-kit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F://indexing.txt', mode='r') as f:\n",
    "    text= f.read()\n",
    "\n",
    "doc = text.split('\\n') # converts into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Virat smashed another ton in One day International',\n",
       " 'Rohit Sharma is highest run score in T20 International',\n",
       " 'Gold prices rise high, after sharp fall',\n",
       " 'Farms fires in Punjab, seven times more than in Haryana',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(doc,columns=['documents'])\n",
    "df.drop(index=4,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 'Who got highest runs in cricket'  # query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Normalization:\n",
    "- Lower\n",
    "- Remove special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9 ]','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc_tp']= df['documents'].apply(textprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2fd802753cca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVERSION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'version'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>doc_tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat smashed another ton in One day Internati...</td>\n",
       "      <td>virat smashed another ton in one day internati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit Sharma is highest run score in T20 Inter...</td>\n",
       "      <td>rohit sharma is highest run score in t20 inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold prices rise high, after sharp fall</td>\n",
       "      <td>gold prices rise high after sharp fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farms fires in Punjab, seven times more than i...</td>\n",
       "      <td>farms fires in punjab seven times more than in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  Virat smashed another ton in One day Internati...   \n",
       "1  Rohit Sharma is highest run score in T20 Inter...   \n",
       "2            Gold prices rise high, after sharp fall   \n",
       "3  Farms fires in Punjab, seven times more than i...   \n",
       "\n",
       "                                              doc_tp  \n",
       "0  virat smashed another ton in one day internati...  \n",
       "1  rohit sharma is highest run score in t20 inter...  \n",
       "2             gold prices rise high after sharp fall  \n",
       "3  farms fires in punjab seven times more than in...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatizatiom**\n",
    "- process of extracting root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Home\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet    #pretrained RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lema = wordnet.WordNetLemmatizer()  # intializing lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lema.lemmatize('loving',pos='v')\n",
    "#n-noun, v-verb,r-adverb,a-adjective...etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parts of speech tagging:(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virat smashed another ton in one day international'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = df['doc_tp'][0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to C:\\Users\\Home\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('virat', 'NN'), ('smashed', 'VBD'), ('another', 'DT'), ('ton', 'NN'), ('in', 'IN'), ('one', 'CD'), ('day', 'NN'), ('international', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "tag_list = pos_tag(nltk.word_tokenize(sent),tagset=None)   # tagset = 'universal'\n",
    "print(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google pos tag list in nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smash'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lema.lemmatize('smashed',pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('virat', 'NN'), ('smashed', 'VBD'), ('another', 'DT'), ('ton', 'NN'), ('in', 'IN'), ('one', 'CD'), ('day', 'NN'), ('international', 'JJ')]\n",
      "[('rohit', 'NN'), ('sharma', 'NN'), ('is', 'VBZ'), ('highest', 'JJS'), ('run', 'NN'), ('score', 'NN'), ('in', 'IN'), ('t20', 'JJ'), ('international', 'JJ')]\n",
      "[('gold', 'NN'), ('prices', 'NNS'), ('rise', 'VBP'), ('high', 'JJ'), ('after', 'IN'), ('sharp', 'JJ'), ('fall', 'NN')]\n",
      "[('farms', 'NNS'), ('fires', 'NNS'), ('in', 'IN'), ('punjab', 'NN'), ('seven', 'CD'), ('times', 'NNS'), ('more', 'JJR'), ('than', 'IN'), ('in', 'IN'), ('haryana', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for sent1 in df['doc_tp']:\n",
    "    from nltk import pos_tag\n",
    "    x=pos_tag(nltk.word_tokenize(sent1),tagset=None)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_lema(sentence):\n",
    "    #computing parts of speech\n",
    "    tag_list= pos_tag(nltk.word_tokenize(sentence),\n",
    "                      tagset=None)\n",
    "    lema_sent =[]# initializing empty list\n",
    "    for token,pos_token in tag_list:\n",
    "        if token in stop: # removing stopwords\n",
    "            continue\n",
    "            \n",
    "        if pos_token.startswith('V'): #verb\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'):  #adjective\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'): #adverb\n",
    "            pos_val= 'r'\n",
    "        else:  # any pos except verb, adj , adverb\n",
    "            pos_val='n'\n",
    "\n",
    "        lema_token = lema.lemmatize(token,pos_val)# computing\n",
    "        lema_sent.append(lema_token)#append values in list\n",
    "    return \" \".join(lema_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Text: virat smashed another ton in one day international\n",
      "Lemmatization clean Text: virat smash another ton one day international\n"
     ]
    }
   ],
   "source": [
    "print('Clean Text:',sent)\n",
    "print('Lemmatization clean Text:',sent_lema(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>doc_tp</th>\n",
       "      <th>doc_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat smashed another ton in One day Internati...</td>\n",
       "      <td>virat smashed another ton in one day internati...</td>\n",
       "      <td>virat smash another ton one day international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit Sharma is highest run score in T20 Inter...</td>\n",
       "      <td>rohit sharma is highest run score in t20 inter...</td>\n",
       "      <td>rohit sharma high run score t20 international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold prices rise high, after sharp fall</td>\n",
       "      <td>gold prices rise high after sharp fall</td>\n",
       "      <td>gold price rise high sharp fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farms fires in Punjab, seven times more than i...</td>\n",
       "      <td>farms fires in punjab seven times more than in...</td>\n",
       "      <td>farm fire punjab seven time haryana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  Virat smashed another ton in One day Internati...   \n",
       "1  Rohit Sharma is highest run score in T20 Inter...   \n",
       "2            Gold prices rise high, after sharp fall   \n",
       "3  Farms fires in Punjab, seven times more than i...   \n",
       "\n",
       "                                              doc_tp  \\\n",
       "0  virat smashed another ton in one day internati...   \n",
       "1  rohit sharma is highest run score in t20 inter...   \n",
       "2             gold prices rise high after sharp fall   \n",
       "3  farms fires in punjab seven times more than in...   \n",
       "\n",
       "                                       doc_lemma  \n",
       "0  virat smash another ton one day international  \n",
       "1  rohit sharma high run score t20 international  \n",
       "2                gold price rise high sharp fall  \n",
       "3            farm fire punjab seven time haryana  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['doc_lemma']= df['doc_tp'].apply(sent_lema)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Home\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#stop = stopwords.words('english')\n",
    "#print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>doc_tp</th>\n",
       "      <th>doc_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat smashed another ton in One day Internati...</td>\n",
       "      <td>virat smashed another ton in one day internati...</td>\n",
       "      <td>virat smash another ton one day international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit Sharma is highest run score in T20 Inter...</td>\n",
       "      <td>rohit sharma is highest run score in t20 inter...</td>\n",
       "      <td>rohit sharma high run score t20 international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gold prices rise high, after sharp fall</td>\n",
       "      <td>gold prices rise high after sharp fall</td>\n",
       "      <td>gold price rise high sharp fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farms fires in Punjab, seven times more than i...</td>\n",
       "      <td>farms fires in punjab seven times more than in...</td>\n",
       "      <td>farm fire punjab seven time haryana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  Virat smashed another ton in One day Internati...   \n",
       "1  Rohit Sharma is highest run score in T20 Inter...   \n",
       "2            Gold prices rise high, after sharp fall   \n",
       "3  Farms fires in Punjab, seven times more than i...   \n",
       "\n",
       "                                              doc_tp  \\\n",
       "0  virat smashed another ton in one day internati...   \n",
       "1  rohit sharma is highest run score in t20 inter...   \n",
       "2             gold prices rise high after sharp fall   \n",
       "3  farms fires in punjab seven times more than in...   \n",
       "\n",
       "                                       doc_lemma  \n",
       "0  virat smash another ton one day international  \n",
       "1  rohit sharma high run score t20 international  \n",
       "2                gold price rise high sharp fall  \n",
       "3            farm fire punjab seven time haryana  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding:\n",
    "- Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv= CountVectorizer()\n",
    "X= cv.fit_transform(df['doc_lemma']).toarray()   # converting text to bag of words\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'day', 'fall', 'farm', 'fire', 'gold', 'haryana', 'high', 'international', 'one', 'price', 'punjab', 'rise', 'rohit', 'run', 'score', 'seven', 'sharma', 'sharp', 'smash', 't20', 'time', 'ton', 'virat']\n"
     ]
    }
   ],
   "source": [
    "features = cv.get_feature_names()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>another</th>\n",
       "      <th>day</th>\n",
       "      <th>fall</th>\n",
       "      <th>farm</th>\n",
       "      <th>fire</th>\n",
       "      <th>gold</th>\n",
       "      <th>haryana</th>\n",
       "      <th>high</th>\n",
       "      <th>international</th>\n",
       "      <th>one</th>\n",
       "      <th>...</th>\n",
       "      <th>run</th>\n",
       "      <th>score</th>\n",
       "      <th>seven</th>\n",
       "      <th>sharma</th>\n",
       "      <th>sharp</th>\n",
       "      <th>smash</th>\n",
       "      <th>t20</th>\n",
       "      <th>time</th>\n",
       "      <th>ton</th>\n",
       "      <th>virat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   another  day  fall  farm  fire  gold  haryana  high  international  one  \\\n",
       "0        1    1     0     0     0     0        0     0              1    1   \n",
       "1        0    0     0     0     0     0        0     1              1    0   \n",
       "2        0    0     1     0     0     1        0     1              0    0   \n",
       "3        0    0     0     1     1     0        1     0              0    0   \n",
       "\n",
       "   ...  run  score  seven  sharma  sharp  smash  t20  time  ton  virat  \n",
       "0  ...    0      0      0       0      0      1    0     0    1      1  \n",
       "1  ...    1      1      0       1      0      0    1     0    0      0  \n",
       "2  ...    0      0      0       0      1      0    0     0    0      0  \n",
       "3  ...    0      0      1       0      0      0    0     1    0      0  \n",
       "\n",
       "[4 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow = pd.DataFrame(X,columns=features)\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who got highest runs in cricket'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find similar sentences:\n",
    "Q # my query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who got highest runs in cricket\n",
      "get high run cricket\n",
      "[[0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#step-1---> cleaning\n",
    "Q_clean= textprocess(Q)   # function is above\n",
    "#step-2---> Lemmetaization\n",
    "Q_lema = sent_lema(Q_clean)\n",
    "#step-3 --> convert into bag of words with same dimmenssions as yours= corpus\n",
    "Q_bow = cv.transform([Q_lema]).toarray()\n",
    "print(Q_clean)\n",
    "print(Q_lema)\n",
    "print(Q_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine simmilarity\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw= pairwise_distances(X,Q_bow,metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.53452248],\n",
       "       [0.28867513],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos=1-pw\n",
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similarity index position 1 and similarity value=[0.53452248]\n"
     ]
    }
   ],
   "source": [
    "ind = cos.argmax()\n",
    "print('Most similarity index position {} and similarity value={}'.format(ind, cos[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jacard index(intersection over union)\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate it then it will work\n",
    "Q_bow_repeat = Q_bow.repeat(len(df),axis=0)#4---> no.of repition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.28571429, 0.14285714, 0.        ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js= jaccard_score(X.T,Q_bow_repeat.T,average=None)\n",
    "js\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## TFIDF(Term Frequency Inverse Document Frequency)\n",
    " tfidf = log(tf+1)*log(N/df+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38861429, 0.38861429, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30638797, 0.38861429,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.38861429,\n",
       "        0.        , 0.        , 0.38861429, 0.38861429],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31553666, 0.31553666, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40021825, 0.40021825,\n",
       "        0.40021825, 0.        , 0.40021825, 0.        , 0.        ,\n",
       "        0.40021825, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.42176478, 0.        , 0.        ,\n",
       "        0.42176478, 0.        , 0.3325242 , 0.        , 0.        ,\n",
       "        0.42176478, 0.        , 0.42176478, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.42176478, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.40824829, 0.40824829,\n",
       "        0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.40824829, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf = tfidf.fit_transform(df['doc_lemma']).toarray()\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot dataset -----> cosine simmilarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
